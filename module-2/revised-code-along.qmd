---
title: "How to Split Data into Training and Testing Sets"
subtitle: "Code Along"
format:
  revealjs: 
    slide-number: c/t
    progress: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: img/LASERLogoB.png
    theme: [default, css/laser.scss]
    width: 1920
    height: 1080
    margin: 0.05
    footer: <a href=https://www.go.ncsu.edu/laser-institute>go.ncsu.edu/laser-institute
---

```{r}
#| include: false
```

```{r}
#| echo: false
# then load all the relevant packages
pacman::p_load(pacman, knitr, tidyverse, readxl)
```

# Getting started

## Process

-   Again, create an `.R` (or `.py`) file --- this time in `/module-2`
-   Then, run copy and paste the code in this presentation as we talk through each step

## Quick discussion

-   Which parts of the supervised machine learning process is most unclear?

# Code-along: R

::: panel-tabset
## 0

**Loading, setting up**

```{r}
#| eval: false
#| echo: true
library(tidyverse)
library(tidymodels)
library(janitor)

# Load IPEDS data
ipeds <- read_csv("data/ipeds-all-title-9-2022-data.csv") %>%
  clean_names()

# Select and rename variables
ipeds <- ipeds %>% 
  select(name = institution_name, 
         title_iv = hd2022_postsecondary_and_title_iv_institution_indicator,
         carnegie_class = hd2022_carnegie_classification_2021_basic,
         state = hd2022_state_abbreviation,
         total_enroll = drvef2022_total_enrollment,
         pct_admitted = drvadm2022_percent_admitted_total,
         n_bach = drvc2022_bachelors_degree,
         n_mast = drvc2022_masters_degree,
         n_doc = drvc2022_doctors_degree_research_scholarship,
         tuition_fees = drvic2022_tuition_and_fees_2021_22,
         grad_rate = drvgr2022_graduation_rate_total_cohort,
         percent_fin_aid = sfa2122_percent_of_full_time_first_time_undergraduates_awarded_any_financial_aid,
         avg_salary = drvhr2022_average_salary_equated_to_9_months_of_full_time_instructional_staff_all_ranks)

# Filter for Title IV institutions and those with Carnegie classification
ipeds <- ipeds %>%
  filter(title_iv == "Title IV postsecondary institution") %>%
  filter(carnegie_class != "Not applicable, not in Carnegie universe (not accredited or nondegree-granting)")

# Create binary outcome variable
ipeds <- ipeds %>%
  mutate(good_grad_rate = if_else(grad_rate > 60, 1, 0),
         good_grad_rate = as.factor(good_grad_rate))

# Take a quick glimpse
glimpse(ipeds)
```

## 1

**Split data**

```{r}
#| echo: true
#| eval: false

# Set a seed for reproducibility
set.seed(20230712)

# Create a split with 80% of data for training and 20% for testing
ipeds_split <- initial_split(ipeds, prop = 0.8, strata = "good_grad_rate")

# Extract the training and testing sets
train_data <- training(ipeds_split)
test_data <- testing(ipeds_split)

# Check dimensions of each set
dim(train_data)
dim(test_data)
```

## 2

**Engineer features**

```{r}
#| echo: true
#| eval: false

# Create our recipe with the features we want to use
ipeds_recipe <- recipe(good_grad_rate ~ total_enroll + pct_admitted + 
                      tuition_fees + percent_fin_aid + avg_salary, 
                     data = train_data) %>%
  # Create a new feature - ratio of bachelor's degrees to enrollment
  step_mutate(bach_ratio = n_bach / total_enroll) %>%
  # Normalize all numeric predictors to have mean 0 and SD 1
  step_normalize(all_numeric_predictors())
```

## 3

**Specify recipe, model, and workflow**

```{r}
#| echo: true
#| eval: false

# Specify the model - logistic regression for classification
my_mod <- logistic_reg() %>%
    set_engine("glm") %>%
    set_mode("classification")

# Combine model and recipe into a workflow
my_wf <- workflow() %>%
    add_recipe(ipeds_recipe) %>%
    add_model(my_mod)

# View the workflow
my_wf
```

## 4

**Fit model**

```{r}
#| echo: true
#| eval: false

# Fit the model using the training data and evaluate on testing data
log_reg_fit <- last_fit(my_wf, ipeds_split)
```

## 5

**Evaluate accuracy**

```{r}
#| echo: true
#| eval: false

# Collect performance metrics
collect_metrics(log_reg_fit)
```

## 6

**Visualize predictions**

```{r}
#| echo: true
#| eval: false

# Collect predictions
predictions <- collect_predictions(log_reg_fit)

# Create a plot of predicted probabilities
ggplot(predictions, aes(x = .pred_1, fill = good_grad_rate)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
  labs(title = "Predicted Probabilities by Actual Graduation Rate Category",
       x = "Predicted Probability of Good Graduation Rate",
       y = "Count",
       fill = "Actual Graduation Rate") +
  theme_minimal()
```
:::

## Python code

```{python}
#| eval: false
#| echo: true

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Load IPEDS data
ipeds_df = pd.read_csv("data/ipeds-all-title-9-2022-data.csv")

# Clean column names
ipeds_df.columns = ipeds_df.columns.str.lower().str.replace('[^0-9a-zA-Z]+', '_')

# Select and rename columns
column_map = {
    'institution_name': 'name',
    'hd2022_postsecondary_and_title_iv_institution_indicator': 'title_iv',
    'hd2022_carnegie_classification_2021_basic': 'carnegie_class',
    'hd2022_state_abbreviation': 'state',
    'drvef2022_total_enrollment': 'total_enroll',
    'drvadm2022_percent_admitted_total': 'pct_admitted',
    'drvc2022_bachelors_degree': 'n_bach',
    'drvc2022_masters_degree': 'n_mast',
    'drvc2022_doctors_degree_research_scholarship': 'n_doc',
    'drvic2022_tuition_and_fees_2021_22': 'tuition_fees',
    'drvgr2022_graduation_rate_total_cohort': 'grad_rate',
    'sfa2122_percent_of_full_time_first_time_undergraduates_awarded_any_financial_aid': 'percent_fin_aid',
    'drvhr2022_average_salary_equated_to_9_months_of_full_time_instructional_staff_all_ranks': 'avg_salary'
}

ipeds_df = ipeds_df.rename(columns=column_map)
ipeds_df = ipeds_df[column_map.values()]

# Filter for Title IV institutions and those with Carnegie classification
ipeds_df = ipeds_df[ipeds_df['title_iv'] == "Title IV postsecondary institution"]
ipeds_df = ipeds_df[ipeds_df['carnegie_class'] != "Not applicable, not in Carnegie universe (not accredited or nondegree-granting)"]

# Create binary outcome
ipeds_df['good_grad_rate'] = np.where(ipeds_df['grad_rate'] > 60, 1, 0)

# Create feature - bachelor's ratio
ipeds_df['bach_ratio'] = ipeds_df['n_bach'] / ipeds_df['total_enroll']

# Drop rows with missing values for our predictors
ipeds_df = ipeds_df.dropna(subset=['total_enroll', 'pct_admitted', 'tuition_fees', 
                                    'percent_fin_aid', 'avg_salary', 'good_grad_rate'])

# Split features and target
X = ipeds_df[['total_enroll', 'pct_admitted', 'tuition_fees', 
              'percent_fin_aid', 'avg_salary', 'bach_ratio']]
y = ipeds_df['good_grad_rate']

# Split into training and testing sets (80/20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define and train the model
model = LogisticRegression(random_state=42)
model.fit(X_train_scaled, y_train)

# Make predictions
y_pred = model.predict(X_test_scaled)
y_pred_proba = model.predict_proba(X_test_scaled)[:,1]

# Evaluate the model
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Plot predicted probabilities
plt.figure(figsize=(10, 6))
for i, label in enumerate(['Low Graduation Rate', 'High Graduation Rate']):
    mask = y_test == i
    plt.hist(y_pred_proba[mask], alpha=0.5, label=label, bins=20)

plt.xlabel('Predicted Probability of High Graduation Rate')
plt.ylabel('Count')
plt.title('Predicted Probabilities by Actual Graduation Rate Category')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

# Discussion

-   In the big picture, what is the use of the training data relative to the testing data?
