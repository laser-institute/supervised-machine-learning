---
title: "How to Split Data into Training and Testing Sets"
subtitle: "Code Along"
format:
  revealjs: 
    slide-number: c/t
    progress: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: img/LASERLogoB.png
    theme: [default, css/laser.scss]
    width: 1920
    height: 1080
    margin: 0.05
    footer: <a href=https://www.go.ncsu.edu/laser-institute>go.ncsu.edu/laser-institute
---

```{r}
#| include: false
```

```{r}
#| echo: false
# then load all the relevant packages
pacman::p_load(pacman, knitr, tidyverse, readxl)
```

# Getting started

## Process

- Again, create an `.R` (or `.py`) file --- this time in `/module-2`
- Then, run copy and paste the code in this presentation as we talk through each step

## Quick discussion

- Which parts of the supervised machine learning process is most unclear?

# Code-along

## R Code

::: {.panel-tabset}

## 0

**Loading, setting up**

```{r}
#| eval: false
#| echo: true
library(tidyverse)
library(tidymodels)

pokemon <- read_csv("data/pokemon-data.csv")

pokemon %>% 
    glimpse()
```

## 1

**Split data**

```{r}
#| echo: true
#| eval: false

pokemon_split <- initial_split(pokemon, prop = 0.8)
train <- training(pokemon_split)
test <- testing(pokemon_split)
```

## 2

**Engineer features**

```{r}
#| echo: true
#| eval: false

pokemon_recipe <- recipe(early_gen ~ height_m + weight_kg + hp, 
                         data = train) %>% 
    step_mutate(early_gen = as.factor(early_gen))
```

## 3

**Specify recipe, model, and workflow**

```{r}
#| echo: true
#| eval: false

my_mod <- logistic_reg() %>%
    set_engine("glm") %>%
    set_mode("classification")

my_wf <- workflow() %>%
    add_recipe(pokemon_recipe) %>%
    add_model(my_mod)
```

## 4

**Fit model**

```{r}
#| echo: true
#| eval: false

log_reg_fit <- last_fit(my_wf, pokemon_split)
```

## 5

**Evaluate accuracy**

```{r}
#| echo: true
#| eval: false

collect_metrics(log_reg_fit)
```

:::

## python code

*AR edit*

```{python}
#| eval: false
#| echo: true


```

# Discussion

- In the big picture, what is the use of the training data relative to the testing data?