---
title: "Adding Metrics to a Workflow"
subtitle: "Code Along"
format:
  revealjs: 
    slide-number: c/t
    progress: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: img/LASERLogoB.png
    theme: [default, css/laser.scss]
    width: 1920
    height: 1080
    margin: 0.05
    footer: <a href=https://www.go.ncsu.edu/laser-institute>go.ncsu.edu/laser-institute
---

```{r}
# load all the relevant packages
pacman::p_load(pacman, knitr, tidyverse, readxl)
```

# Getting started

## Process

- Again, create a .R file in `/module-3`
- Then, run copy and paste the code in this presentation as we talk through each step

## Quick discussion

- What are the benefits of using metrics beyond "Accuracy"?
- Why is feature engineering a useful step?

# Code-along: R

::: {.panel-tabset}
## 0.

**Loading, setting up: create a .R file in /module-3 and run this code**

```{r}
#| eval: false
#| echo: true
library(tidyverse)
library(tidymodels)

pokemon <- read_csv("data/pokemon-data.csv")

pokemon %>%
    glimpse()

pokemon %>% 
    count(early_gen) # distribution of early vs later generations
```

## 1.

```{r}
#| eval: false
#| echo: true
train_test_split <- initial_split(pokemon, prop = .70)

data_train <- training(train_test_split)
```

## 2.

```{r}
#| eval: false
#| echo: true
# predicting early generation status based on height, weight, and HP
my_rec <- recipe(early_gen ~ height_m + weight_kg + hp, data = data_train) %>% 
    step_mutate(early_gen = as.factor(early_gen))
```

## 3.

```{r}
#| eval: false
#| echo: true
my_mod <-
    logistic_reg() %>% 
    set_engine("glm") %>%
    set_mode("classification")

my_wf <-
    workflow() %>%
    add_model(my_mod) %>% 
    add_recipe(my_rec)
```

## 4.

**Model building with training data**

```{r}
#| eval: false
#| echo: true
class_metrics <- metric_set(accuracy, sensitivity, specificity, ppv, npv, kap) # this is new
final_fit <- last_fit(my_wf, train_test_split, metrics = class_metrics)
```

## 4.

**Model evaluating with testing data**

```{r}
#| eval: false
#| echo: true
fit_model <- fit(my_wf, data_train)

predictions <- predict(fit_model, data_train) %>% 
    bind_cols(data_train) %>% 
    mutate(early_gen = as.factor(early_gen))

predictions %>%
    metrics(early_gen, .pred_class) %>%
    filter(.metric == "accuracy")
```

## 5.

**Only run this once you're done training/messing with your model!; this way, these estimates will be unbiased**

```{r}
#| eval: false
#| echo: true
final_fit %>%
    collect_metrics()
```

:::

# Code-along: python

**AR, separate into the same steps as above?**

```{python}

```

# Discussion

- What are things you consider when choosing which metric(s) to interpret for a particular analysis?